## 数据挖掘思考

```flow
st=>start: 数据
e=>end: 结果
op1=>operation: 特征


st->op1->e
```

上图中的数据是数据准备后的结果，特征是特征工程后的结果，结果是构造模型后生成的结果。

数据挖掘大致都可分为三个过程，数据准备，特征工程，构造模型。三个过程主要是以上图中流程图所示，但实际应用中常常会多次反向循环迭代，特征工程时可能需要补充数据，再次进行数据准备；建模时效果不好，重新构造特征；建模时效果不好，重新补充数据等等，我们需要根据实际情况来不断调整上述三个过程中的任一过程。下面我们就来详细介绍一下这三个过程。

### 数据准备

数据准备，顾名思义，就是准备用于建模解决的问题的数据。对于数据挖掘，其本质是发现数据中的信息（隐藏的规律），没有数据，一切就是无源之水，任你特征工程，构造模型能力再强，经验再丰富，依然无法解决问题。因此，数据准备需要有大量的数据。有了足够的数据，我们可以去发现数据中的信息了，但由于我们建模一般是为了解决特定的问题，所以我们还需要判断数据是否蕴含解决相关问题的信息，或者说数据中是否蕴含着足够的信息来解决特定的问题。如果数据中蕴含的信息量不足，那么后面的工作无论做得怎样都不会有解决这类问题的好的结果。因为数据挖掘只能将数据蕴含的信息挖掘出来，而无法将数据本身不存在的信息挖掘出来。即无法从数据中获得超过其本身信息量的信息。因此，我们需要蕴含了解决特定问题信息的数据。由于对于数据中蕴含的信息是否包含解决问题的信息是难以确定的，所以我们常常会在后面的两个阶段中进行数据的补充，通过后面的应用来发现数据中的不足。另外，问题的相关领域知识，会使我们在初次做数据准备时包含更多的有用信息。

有了包含解决问题信息的足够数据之后，才能去发现数据中隐藏的规律。常用的发现规律的两种方式是：规则、模型。

规则是通过人工去寻找规律，利用人员的相关领域知识和对数据的敏感性来发现隐藏在数据中的规律。利用这种方法常常可以快速的取得不错的效果，并且利用人工提取出的规则常常会具有较高的鲁棒性。但是这种方法也有一些缺陷，即对人工的水平要求很高，数据情况越复杂，则对个人的能力要求越高。如果数据过于复杂，将可能人工完全无法发现规律。

模型则是利用数学方式去寻找规律。由于传统的模型的输入是需要为矩阵格式，而数据本身是有着文本，数字，音频，图像等多种方式，所以需要人工构造特征，来将特征作为输入输入到模型中。在深度学习的模型中，如cnn，lstm等都可以利用模型自身来构造特征，在一个模型中完成特征工程和构建模型两个过程，由于两个过程在一个模型中完成，所以效果一般会优于传统模型的效果。

### 特征工程

在做传统（非图像，文本等）数据的数据挖掘时，我们需要将数据中蕴含的相关信息以模型可以接受的格式进行输入。这个过程就是特征工程。在深度学习火起来之前，数据挖掘很大一部分工作是在进行特征工程，因为数据准备工作中，通常需要依赖其他部门的配合，是一个短期内数据挖掘人员无能为力的工作。在数据准备好后，短期内数据是不太容易产生变化，所有数据挖掘人员可以决定的就是后面两个过程。而在构建模型中，相同的特征，使用不同的模型所产生的结果差异是比较小的，一般不会超过10%。而对于同样的数据，特征工程的好坏，可以使同一模型的结果差异在20%以上。因此特征工程是数据挖掘人员最核心的能力。但是特征工程也是数据挖掘中资料最少的一个环节，常常需要靠个人的经验积累和业务理解。

在深度学习算法当中，特征构建和模型构建被结合在一起，避免了人为构造特征的过程，可以科学有效的减少信息从数据源到构建特征过程中的信息损失，提高了结果可能包含的信息上限。

### 构建模型

构建模型是利用特征工程构造好的特征来训练模型，使模型学到特征中的信息，并将其应用在特定问题或新的数据中。

因为模型使用的是特征工程或者模型自动提取的特征，这个过程总会或多或少损失一些数据中的信息，所以特征只会包含数据中蕴含全部信息的部分，体现在构建模型中就是，模型或规则最终发掘的信息是特征中蕴含的信息。在构建模型中利用不同的模型算法，也只是在尽可能减少特征中的信息损失，所以无论算法多么优秀，结果都会有一个上限，就是特征中包含的全部信息。

### 总结

因此，数据挖掘是一个信息逐渐丢失的过程，从数据到特征，从特征到结果，每一步都会丢失一些信息。我们在数据挖掘中做得一切努力，都不过是在减少信息的丢失。所以如果结果很好，必然是数据，特征，模型每一步都做得近乎完美，使得信息在整个传输链条中损失很少。而如果最后的模型结果不好，则可能是其中任意一步做得不好，可是由于模型是在链条的最后一个环节，是离输出结果最近的环节，所以常常会把结果不好的原因归到模型做得不好上。在数据挖掘中，模型可以挖掘出的信息的上限就是特征包含的信息，因此前面两个环节没有做好，模型无论怎样优化都不会取得很好的效果。但是因为数据和特征中包含的对于结果的信息量常常是难以估算的，所以难以估量是否结果不好是由于模型太差无法挖掘出特征中蕴含的信息，对此我们需在一段时间模型优化没有效果后，就认为模型已经挖掘了特征的全部信息，需要增加特征和数据的信息量，才能进一步提高结果的信息量。

