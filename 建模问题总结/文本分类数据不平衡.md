## 文本分类数据不平衡

在对客户录音文本进行分类过程中，初始使用训练集测试准确率为95%，到实际数据上进行测试时，出现了准确率急速下降，变成0.008。这是因为在生成训练集和测试集时为了模型更好拟合，使用了过采样，使两种类别的比例近似为1:1。而当在实际数据上进行测试时，（1）由于数据的变动，导致模型的准确率可能会下降。（2）由于0,1分类中，类型0的文本是类型1的文本的1600多倍，导致在识别类型1的数目不变得情况下，类型0的误识别数目变为原来的1600多倍。在两者综合影响下准确率就变成一个接近0的极小数。

解决方案：

1. 考虑通过使用异常值发现算法（Isolation Forest、one_class的svm、EllipticEnvelope），文本分类通常维度都较高，在高维空间下，文本向量相对总是稀疏，所以较难有效的发现异常值。考虑通过pca，聚类等方法进行降维，再用降维后的数据进行异常值发现。
2. 考虑进行人为构建boosting，将分类错误的文本和类型1的全部文本重新构建模型，预测后再次将预测错误的与类型1的文本合并构建新的模型，通过这种迭代来达到提高准确率的效果。