## word2vec的妙用

众所周知，word2vec是在文本任务时产生的。通常也主要用于文本的相关任务：

1. 找相关词，注意是相关词而不是同义词。例如你输入”雷军”，计算出来的相关词就会有:手机，小米，乔布斯等等。

2. 根据上下文预测句子中缺失的单词

3. 根据不同语种里相同单词的词向量之间的特定关系做机器翻译。

4. 由词向量构建句子向量。

  ​

但是，word2vec实际上是提出了一种word2vec提供了一种计算关联的新思路，通过转化为term向量的方式，可以计算出任何term之间的关联度。通俗的说，word2vec就是一种将‘词’变成‘向量’ 的工具，在nlp的场景中‘词’是显而易见的，但是在有些时候，什么可以看做‘词’和‘文档’就不那么容易了。

### 在社交网络中的推荐

给当前用户推荐他可能关注的『大V』。对一个新用户，此题基本无解，如果在已知用户关注了几个『大V』之后，相当于知道了当前用户的一些关注偏好，根据此偏好给他推荐和他关注过大V相似的大V，就是一个很不错的推荐策略。所以，如果可以求出来任何两个V用户的相似度，上面问题就可以基本得到解决。

我们知道word2vec中两个词的相似度可以直接通过余弦来衡量，接下来就是如何将每个V用户变为一个词向量的问题了。巧妙的地方就是如何定义doc和word，针对上面问题，可以将doc和word定义为：

```
word ->   每一个大V就是一个词
doc  ->   根据每一个用户关注大V的顺序，生成一篇文章
```

由于用户量很大（大约4亿），可以将关注word个数少的doc删掉，因为本身大V的种类是十万级别（如果我没记错的话）， 选择可以覆盖绝大多数大V的文章数量就足够了。

### 商品推荐

在商品推荐的场景中，竞品推荐和搭配推荐的时候都有可能需要计算任何两个商品的相似度，根据浏览/收藏/下单/App下载等行为，可以将商品看做词，将每一个用户的一类行为序看做一个文档，通过word2vec将其训练为一个向量。之后可以进行用户推荐用户已有商品的相似商品（通过商品间的余弦相似度）。或者将其当成nlp任务，作序列预测，预测用户可能安装的下一个商品，进行推荐。

同样的，在计算广告中，根据用户的点击广告的点击序列，将每一个广告变为一个向量。变为向量后，用此向量可以生成特征融入到rank模型中。

