## chatbot简单思考

现有的聊天机器人聊起天来很像人工智障，究其原因，是无法有效的理解语言所指代的含义，无法将语言符号和真实世界建立有效的映射关系。现有的chatbot使用的是seq2seq+attention模型，只是通过统计的方法对语言进行机械的学习，虽然可以将语言转换到一个特定的语言相对向量空间，但是不能建立起与真实世界的映射，那么bot的回答就只能是根据学习的到规则将相对向量空间中的向量映射回语言中，这样的bot对于语言是没有任何理解的，如果想要bot对语言内容有所理解，就需要将内容和真实世界建立映射，或者说是真实空间建立映射，而不只是简单的映射到一个没有什么实际意义的向量空间。如果bot无法对真实世界（或真实空间）建立映射，就无法摆脱人工智障的境地。

思考nlp中的其他任务，其实可以理解为在向这个方向努力。

word2vec，将词映射到向量空间，可以得到词与词之间的相对位置，因为词性相近的词，在使用上也会有相似的上下文关联。但是无法得到词的绝对位置，即某个词或者某类词，究竟代表着什么。我们希望这个词向量可以和我们的世界有一个真实的映射。在做图片描述，也就是将词向量的映射和图片中的某些像素关联起来，形成一个映射。

nmt常用的方法也是seq2seq+attention，但是翻译系统效果要比聊天机器人要好很多，可能一部分原因是，翻译系统并不涉及对内容的理解，只是将语言从A转换到B。对于这种任务模型只要生成一个对语言进行映射的相对向量空间，再通过建立语言和向量空间之间的映射，就可以完成翻译工作，无需和真实世界建立映射关系。

### 知识图谱

对于向量空间内无法和真实世界产生映射，可以考虑搭建知识库来完成对真实世界的映射。通过这种方式来达到将文本中实体（即名词）映射到真实世界，这种特殊的知识库，可以被称为知识图谱。

对于非名词类的语言，需要如何理解，继续思考。

当有了对语义的理解，将可以准确的回答一些逻辑性的问题。本质上有点像一个规则库。

而要回答一些带有主观意识的问题，需要bot能够产生自我意识。自我意识的起源，就需要我们思考人的意识产生来尝试创造。