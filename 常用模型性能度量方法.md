# 常用模型性能度量方法

## 回归

### 均方误差

$$\Large E(f;D)=\frac{1}{m}\sum_{i=1}^{m}(f(x_i)-y_i)^2$$

即预测值和实际值的误差平方和的平均值。

对于更一般的数据分布D和概率密度$p(\cdot)$，均方误差可描述为

$\Large E(f;D)=\int_{x\sim D}(f(x)-y)^2p(x)dx$

## 分类

### 错误率与精度

错误率是分类错误的样本占总样本数的比例，精度是分类正确的样本数占总样本数的比例。

对于数据集$D$,分类错误率定义为：

$\Large E(f;D)=\frac{1}{m}\sum_{i=1}^{m}\alpha(f(x_i)\neq y_i)$

精度定义为：

$$\Large acc(f;D)=\frac{1}{m}\sum_{i=1}^{m}\alpha(f(x_i)=y_i)$$

$\alpha(\cdot)$为指示函数，在$\cdot$为真时取1，假时取0

**优点**：

简单，可直接看出正确率，在非特殊情况下效果不错。

**缺点**：

当样本不均衡时，会导致无法体现模型有效性。即使全部分为大多数，精度和错误率也会很好看。

### F-score

分类结果混淆矩阵

| 真实情况 |  预测结果   |  预测结果   |
| ---- | :-----: | :-----: |
|      |   正例    |   反例    |
| 正例   | TP（真正例） | FN（假反例） |
| 反例   | FP（假正例） | TN（真反例） |

#### 二分类

$\LARGE F_\beta =\frac{(1+\beta^2)\times P\times R}{(\beta ^2\times P)+R}$

$P$为查准率（precision），$R$为查全率(recall)，$F_\beta$为查准率和召回率的加权调和平均。$\frac{1}{F_B}=\frac{1}{1+\beta^2}\cdot(\frac{1}{P}+\frac{\beta^2}{R})$

$\Large P=\frac{TP}{TP+FP}$

$\Large R=\frac{TP}{TP+FN}$

常用的为查准率和召回率的调和平均$F_1$得分。

$\Large F_1=\frac{2\times P\times R}{P+R}$

$F_1$为查准率和召回率的调和平均。$\frac{1}{F_1}=\frac{1}{2}\cdot(\frac{1}{P}+\frac{1}{R})$

#### P-R曲线

y轴为查准率，x轴为查全率。将所有结果按照预测概率从高到底排序，将正例的的阈值为第一个值（即最高值），得到一组当前查准率和查全率，将正例的阈值设为第二个值，得到一组查准率和查全率。。。。依次向下到把所有数据都分为正例，将所有查准率和查全率坐标连起来，即为P-R曲线。


```flow
st=>start: 开始
op1=>operation: 对结果按照预测概率从高到低排序
op2=>operation: 从高到低开始取值作为阈值
op3=>operation: 计算当前查准率和查全率
cond=>condition: 是否结束
e=>end: 将所有的查准率和查全率连起来

st->op1->op2->op3->cond
cond(yes)->e
cond(no)->op3

```

#### 多分类

当多个二分类时，评价模型性能好坏，一种简单的做法是分别计算各个混淆矩阵查准率和查全率，再计算平均值。

宏查准率：

$\Large macro-P=\frac{1}{n}\sum_{i=1}^{n}P_i$

宏查全率：

$\Large macro-R=\frac{1}{n}\sum_{i=1}^{n}R_i$

宏$F_1$：

$\Large macro-F_1=\frac{2\times macro-P\times macor_R}{macre-P+macro-R}$

还可以先将混淆矩阵对应元素进行平均，得到TP、FP、TN、FN的平均值$\TP$。基于这些平均值进行计算$F_1$

微查准率：

$\Large micro-P=\frac{\overline {TP}}{\overline{TP}+\overline{FP}}$

微查全率：

$\Large micro-R=\frac{\overline{TP}}{\overline{TP}+\overline{FN}}$

微$F_1$：

$\Large micro-F_1=\frac{2\times micaro-P\times micor-R}{micro-P+micro-R}$

#### 加权多分类

上面的多分类做平均时对每个分类都赋予相同权重。当针对实际情况时，可能需要对几个二分类模型的结果进行加权平均。

如当进行数据不均衡的分类任务时，为了识别出数量少的类别，可以使权重为$w=\frac{1}{log_2 n}$ ，n为每个类别的数目，通过这种方式对数目少的类别调高权重。

### ROC和AUC

ROC曲线y轴为真正例率（True Positive Rate，简称TPR），x轴为假正例率（False Positive Rate简称FPR）。

$\Large TPR=\frac{TP}{TP+FN}$

$\Large FPR=\frac{FP}{TN+FP}$

在画ROC曲线时，和P-R曲线类似，先根据预测概率由高到低排列，将分类的阈值从最高值依次下降，前一部分为正例，后一部分为反例。

流程：

1. 对预测概率从高到低排序
2. 从原点$(0,0)$开始，依次将每个样例划分为正例
3. 设前一个标记点为$(x,y)$，若当前例为真正例，则标记点坐标为$\Large (x,y+\frac{1}{m^+})$,若当前为假正例，则对应坐标为$(\Large x+\frac{1}{m^-},y)$
4. 将所有相邻点用线连接得到ROC曲线

AUC为ROC曲线下面部分的面积。AUC的面积估算可以用下面公式：

$\Large AUC=\frac{1}{2}\sum_{i=1}^{m-1}(x_{i+1}-x_i)\cdot (y_i+y_{i+1})$

即通过梯形面积取逼近AUC的面积。

## 聚类

> 聚类性能度量主要有两类，一类是将聚类结果与某个“参考模型”进行比较，称为“外部指标”。另一类是直接考察聚类结果而不利用任何参考模型，称为“内部指标”

### 外部指标

对数据集$D=\left\{x_1,x_2,...,x_m \right\}$，假定通过聚类给出的簇划分结果为$C=\left\{C_1,C_2,...,C_k\right\}$,参考模型的簇划分为$C^*=\{C^*_1,C^*_2,...,C^*_s\}$.令$\lambda$和$\lambda^*$分别表示$C$和$C^*$对应的簇标记量。将样本两两配对考虑，定义：

$ a=|SS|,SS=\{(x_i,x_j)|\lambda_i=\lambda_j,\lambda_i^*=\lambda_j^*,i<j\}​$

$ b=|SD|,SD=\{(x_i,x_j)|\lambda_i=\lambda_j,\lambda_i^*\neq\lambda_j^*,i<j\}$

$ c=|DS|,DS=\{(x_i,x_j)|\lambda_i\neq\lambda_j,\lambda_i^*=\lambda_j^*,i<j$

$ d=|DS|,DS=\{(x_i,x_j)|\lambda_i\neq\lambda_j,\lambda_i^*\neq\lambda_j^*,i<j$

其中集合$SS$包含了在$C$中隶属于相同簇且在$C^*$中也隶属于相同簇的样本对，集合$SD$包含了在$C$中隶属于相同簇但在$C^*$中隶属于不同簇的样本对。

基于上面的公式，可以推导出如下指标作为聚类性能度量外部指标。下列指标的结果值均在[0,1]区间，值越大越好。

#### Jaccard系数(Jaccard Coefficint,简称JC)

$\Large JC=\frac{a}{a+b+c}$

#### FM指数（Follow and Mallows Index,简称FMI）

$\Large FMI=\sqrt{\frac{a}{a+b}\cdot\frac{a}{a+c}}$

#### Rand指数（Rand Index,简称RI）

$\Large RI=\frac{2(a+d)}{m(M-1)}$

### 内部指标

聚类结果的簇划分$C=\{C_1,C_2,...,C_k\}$,定义：

$\Large avg(C)=\frac{2}{|C|(|C|-1)}\sum_{1\le{i}<{j}\le|C|}dist(x_i,x_j)$

$\Large diam(C)=max_{1\leq{i}<j\leq|C|}dist(x_i,x_j)$

$\Large d_{min}(C_i,C_j)=min_{x_i\in{C_i},x_j\in{C_j}}dist(x_i,x_j)$

$\Large d_{cen}(C_i,C_j)=dist(u_i,u_j)$

其中，$dist(\cdot,\cdot)$用于计算两个样本间的距离；$u$代表簇$C$的中心点$u=\frac{1}{|C|}\sum_{1\leq{i}\leq{|C|}}x_i$.$avg(C)$代表簇$C$内样本间的平均距离，$diam(C)$表示簇$C$内样本间的最远距离，$d_{min}(C_i,C_j)$表示簇$C_i$与簇$C_j$最近样本间的距离，$d_{cen}(C_i,C_j)$表示簇$C_i$和簇$C_j$中心点间的距离。

基于上面的公式，可以推导出下面这些常用的聚类性能度量内部指标：。

#### DB指数（Davies-Bouldin Index，简称DBI）

DBI的值越小越好

　$\Large DBI=\frac{1}{k}\sum_{i=1}^{k}\max\limits_{j\neq i}(\frac{avg(C_i)+avg(C_j)}{d_{cen(u_i,u_j)}})$

#### Dunn指数（Dunn Index，简称DI）

$\Large DI=\min\limits_{1\le i\le k}\{\min\limits_{j\ne i}(\frac{d_{min}(C_i,C_j)}{max_{1\le l\le k}diam(C_l)})\}$

DI的值越大越好

## 机器翻译评价方法

### BLEU

BLEU是由IBM公司2002年提出的用于自动度量机器翻译效果的评价方法。这个方法的核心思想是：机器翻译越接近专业的人的翻译越好。在此基础下通过计算待评价译文和参考译文的n-gram的相似程度来得到bleu得分。

对于一个待翻译句子，候选译文可以表示为$c_i$，而对应的一组参考译文可以表示为$S_i={s_{i1},s_{i2},...,s_{im}}∈S$ 

n-grams表示n个单词长度的词组集合，令$w_k$表示第k组可能的n-grams 

$h_k(c_i)$表示$w_k$在候选译文$c_i$中出现的次数，$h_k(s_{ij})$表示$ω_k$在参考译文$s_{ij}$中出现的次数 
BLEU则按下式计算对应语句中语料库层面上的重合精度： 
$$
\Large p_n=\frac{\sum_i\sum_k min(h_k(c_i),max_{j\in m}h_k(s_{ij}))}{\sum_i\sum_kh_k(c_i)}
$$
BP为对长度的惩罚函数，c为候选译文长度，r为参考译文长度。
$$
BP=\left\{
\begin{array}{rcl}
1      &      & {c>r}\\
e^{1-r/c}     &      & {c\leq r}\\
\end{array} \right.
$$

BLEU得分：
$$
BLEU=BP\cdot exp(\sum_{n=1}^N w_nlog(p_n))
$$

在log域中，排名效果更明显：
$$
log(BLEU)=min(1-r/c,0)+\sum_{n=1}^Nw_nlog(p_n)
$$


